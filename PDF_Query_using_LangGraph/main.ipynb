{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Query using LangGraph and Google Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries and Variable Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langgraph.graph import Graph  \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.config')\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_data):\n",
    "            \n",
    "    with open(input_data['pdf_file'], 'rb') as pdf_file:\n",
    "        reader = PdfReader(pdf_file)\n",
    "        full_text = \"\".join(page.extract_text() for page in reader.pages)\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "        text_segments = text_splitter.split_text(full_text)\n",
    "\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", api_key=GOOGLE_API_KEY)\n",
    "        \n",
    "        vector_store = FAISS.from_texts(text_segments, embeddings)\n",
    "        vector_store.save_local(\"vectorstore\")\n",
    "        \n",
    "        loaded_vector_store = FAISS.load_local(\"vectorstore\", embeddings, allow_dangerous_deserialization=True)\n",
    "        \n",
    "        return {\n",
    "                \"vector_store\": loaded_vector_store,  \n",
    "                \"query\": input_data['query']\n",
    "            }\n",
    "        \n",
    "def retrieval_generation(input_data):\n",
    "    llm = GoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", api_key=GOOGLE_API_KEY)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=input_data['vector_store'].as_retriever())\n",
    "    response = qa_chain.invoke(input_data['query'])\n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "graph.add_node(\"Preprocess PDF\", preprocessing)\n",
    "graph.add_node(\"RAG Module\", retrieval_generation)\n",
    "\n",
    "graph.add_edge(\"Preprocess PDF\", \"RAG Module\")\n",
    "\n",
    "graph.set_entry_point(\"Preprocess PDF\")\n",
    "graph.set_finish_point(\"RAG Module\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Display the graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_data):\n",
    "    result = app.invoke(input_data)\n",
    "    if \"vector_store\" in result:\n",
    "        input_data['vector_store'] = result['vector_store']\n",
    "    return app.invoke(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide Inputs Here\n",
    "\n",
    "input_data = {\n",
    "    \"pdf_file\": \"news.pdf\",  \n",
    "    \"query\": \"Pravasi Bhartiya Diwas\" \n",
    "}\n",
    "\n",
    "answer = main(input_data)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
