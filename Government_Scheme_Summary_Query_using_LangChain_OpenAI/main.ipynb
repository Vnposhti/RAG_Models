{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF content fetched successfully.\n",
      "Text preprocessed into 47 chunks.\n",
      "Starting summarization process...\n",
      "Summarization completed.\n",
      "\n",
      "Summary for benefits:\n",
      "The PM Street Vendor’s AtmaNirbhar Nidhi (PM SVANidhi) scheme is a central initiative designed to support and empower street vendors who have been adversely impacted by the COVID-19 pandemic. Here is a summary of its key benefits and features:\n",
      "\n",
      "1. **Objective and Scope**: \n",
      "   - The scheme aims to provide financial assistance by facilitating a working capital loan of up to ₹10,000 to street vendors. This helps them restart their businesses which have been affected by the pandemic.\n",
      "   - It is intended to incentivize regular loan repayment and promote digital transactions to enhance creditworthiness.\n",
      "\n",
      "2. **Eligibility**:\n",
      "   - Targeted at street vendors operating in urban areas since or before March 24, 2020.\n",
      "   - Eligible beneficiaries should possess a Certificate of Vending or Identity Card issued by Urban Local Bodies (ULBs).\n",
      "   - Vendors who are identified through surveys or have a Letter of Recommendation from the ULB/Town Vending Committee can also apply.\n",
      "\n",
      "3. **Digital Transactions and Incentives**:\n",
      "   - To promote digital payments, vendors are incentivized with cashbacks ranging from ₹50 to ₹100 based on the number of digital transactions conducted per month.\n",
      "   - This encourages vendors to adopt cashless transactions, potentially improving their credit score and future borrowing capabilities.\n",
      "\n",
      "4. **Interest Subsidy**:\n",
      "   - A 7% interest subsidy is provided on the loans. This subsidy is credited quarterly to the vendor’s account, further reducing the financial burden.\n",
      "   - The subsidy is available until March 31, 2022, and is applicable for subsequent loans on timely repayment.\n",
      "\n",
      "5. **Credit Guarantee**:\n",
      "   - The scheme includes a graded guarantee cover for the loans disbursed. This decreases the risk for lenders and enhances credit availability to vendors.\n",
      "\n",
      "6. **Implementation and Monitoring**:\n",
      "   - The Small Industries Development Bank of India (SIDBI) is the scheme's implementation partner, ensuring effective execution through various financial institutions like banks and microfinance institutions.\n",
      "   - A structured mechanism at Central, State, and ULB levels for steering and monitoring ensures efficient implementation and maximizes the scheme’s reach to targeted beneficiaries.\n",
      "\n",
      "7. **Capacity Building and Financial Literacy**:\n",
      "   - Efforts will be made to enhance the financial literacy of vendors, enabling them to better manage their finances and utilize digital platforms effectively.\n",
      "   - Also focuses on building and transforming Common Interest Groups (CIGs) of street vendors into Joint Liability Groups (JLGs), enhancing their access to credit.\n",
      "\n",
      "8. **Promotion and Branding**:\n",
      "   - Information dissemination through local and social media to ensure that the scheme's benefits reach the intended audience, ensuring a greater impact.\n",
      "\n",
      "Overall, PM SVANidhi seeks to provide much-needed financial support to street vendors, aiming to formalize the sector, promote digital finance culture, and contribute towards achieving the larger goal of making them self-reliant under the AtmaNirbhar Bharat initiative.\n",
      "\n",
      "\n",
      "Summary for application_process:\n",
      "The PM Street Vendor’s AtmaNirbhar Nidhi (PM SVANidhi) scheme is a government initiative aimed at providing micro-credit facilities to street vendors who were adversely affected by the COVID-19 pandemic. The scheme helps formalize and empower street vendors by providing them with working capital loans to resume their businesses.\n",
      "\n",
      "### Application Process for PM SVANidhi Scheme\n",
      "\n",
      "#### Eligibility Criteria\n",
      "1. **State/UT Eligibility**: The scheme is applicable only in those States/UTs which have notified rules under the Street Vendors (Protection of Livelihood and Regulation of Street Vending) Act, 2014. Vendors from Meghalaya may also participate due to its state-specific Street Vendors Act.\n",
      "\n",
      "2. **Vendor Eligibility**:\n",
      "   - Vendors who were engaged in vending in urban areas as of or before March 24, 2020.\n",
      "   - Vendors must possess a Certificate of Vending or ID Card issued by Urban Local Bodies (ULBs).\n",
      "   - Vendors identified in the survey but not issued certificates will get provisional certificates through an IT platform.\n",
      "   - ULB-led surveys or alternate methods can identify other eligible vendors, who can then be issued a Letter of Recommendation (LoR).\n",
      "\n",
      "#### Application Steps\n",
      "1. **Certification**: Eligible street vendors need to have a Certificate of Vending or an Identity Card. Those without these can get a provisional certificate or LoR from ULBs.\n",
      "\n",
      "2. **Loan Application**:\n",
      "   - Vendors may be approached by representatives from Banks, NBFCs, or MFIs or they may approach these financial institutions for a loan application.\n",
      "   - Necessary details will be filled into the IT platform/mobile app provided for the scheme, and verification will occur through an OTP sent to the vendor’s mobile phone.\n",
      "   - Vendors without prior certification need to apply with documentation supporting their street vending status. A local inquiry or membership details can support their application.\n",
      "\n",
      "3. **Verification and Approval**:\n",
      "   - Applications for unrecognized vendors must first be verified by ULB or TVC where they will be issued a provisional LoR, further verified within a fortnight before being forwarded to the lending institution for processing.\n",
      "\n",
      "#### Loan Details\n",
      "- **Loan Amount**: Street vendors can avail a Working Capital loan up to `10,000 with a tenure of 1 year, paid in monthly installments.\n",
      "- **Interest Rates**: Interest rates will vary depending on the type of lending institution, adhering to RBI guidelines.\n",
      "- **Interest Subsidy**: A 7% interest subsidy is available and credited quarterly, only for standard accounts that remain non-NPA.\n",
      "- **Digital Transactions Incentive**: Vendors participating in digital transactions are incentivized with cashback between `50 to `100 based on transaction volumes.\n",
      "\n",
      "#### Other Provisions\n",
      "- **Early Repayment**: Vendors repaying early or on time can avail of subsequent loans with higher credit limits without any prepayment penalties.\n",
      "- **Credit Guarantee**: The scheme provides a graded guarantee cover for loans sanctioned, managed by the Credit Guarantee Fund Trust for Micro and Small Enterprises (CGTMSE).\n",
      "- **Capacity Building**: Efforts are made to build the vendor's capacity for conducting e-Commerce and improve financial literacy.\n",
      "\n",
      "#### Monitoring and Implementation\n",
      "- **National and State Committees**: Committees at the Central, State, and ULB levels ensure effective implementation and monitoring of the scheme.\n",
      "- **Integration with Digital Platforms**: The scheme uses an integrated IT platform to manage processes and facilitate digital transactions.\n",
      "\n",
      "Through these structured steps and provisions, PM SVANidhi aims to aid in the economic recovery and empowerment of street vendors by integrating them into the formal financial system and enhancing their digital presence.\n",
      "\n",
      "\n",
      "Summary for eligibility:\n",
      "The PM Street Vendor’s AtmaNirbhar Nidhi (PM SVANidhi) scheme is aimed at providing affordable loans to street vendors to help them resume their businesses after the COVID-19 pandemic. Here's a breakdown of who is eligible for the scheme:\n",
      "\n",
      "1. **Eligible States/UTs**: \n",
      "   - The scheme is available only in States/UTs that have notified Rules and Scheme under the Street Vendors (Protection of Livelihood and Regulation of Street Vending) Act, 2014.\n",
      "   - Beneficiaries from Meghalaya, which has its own State Street Vendors Act, can also participate.\n",
      "\n",
      "2. **Eligibility Criteria for Beneficiaries**:\n",
      "   - Street vendors engaged in vending in urban areas as of or before March 24, 2020.\n",
      "   - Street vendors in possession of a Certificate of Vending or Identity Card issued by Urban Local Bodies (ULBs).\n",
      "   - Vendors identified in local surveys but not yet issued a Certificate of Vending/Identity Card can also benefit from a provisional Certificate of Vending.\n",
      "   - Street vendors left out of ULB-led identification surveys but recommended by the ULB/Town Vending Committee (TVC) are eligible.\n",
      "   - Vendors from surrounding peri-urban/rural areas vending within ULB limits, if recommended by the ULB/TVC, can apply.\n",
      "\n",
      "3. **Vendors Impacted by COVID-19**:\n",
      "   - Vendors who moved back to their native places during the pandemic lockdown and are likely to return can avail of the loan, provided they meet the eligibility criteria upon their return.\n",
      "\n",
      "Identification documentation for those not covered in surveys might include local state-prepared lists, system-generated requests based on lender recommendations, membership details with vendor associations, or local inquiry reports.\n",
      "\n",
      "Overall, the scheme targets urban street vendors who need financial assistance to restart their businesses affected by the pandemic, aiding them in becoming self-reliant.\n",
      "\n",
      "\n",
      "Summary for documents:\n",
      "The PM Street Vendor’s AtmaNirbhar Nidhi (PM SVANidhi) scheme requires the following documents for identification and to issue a Letter of Recommendation (LoR) for vendors who were left out of surveys or belong to peri-urban or rural areas:\n",
      "\n",
      "1. **Documents for Verification and Recommendation**:\n",
      "   - List of vendors prepared by States/UTs for one-time assistance during lockdown.\n",
      "   - System-generated requests sent to ULBs/TVCs for issuing LoR based on the lender's recommendation after verifying the applicant's credentials.\n",
      "   - Membership details with the vendors' associations.\n",
      "   - Vendor's possession of documents supporting their claim of vending.\n",
      "   - Report of local inquiry conducted by ULB/TVC involving SHGs, Community-Based Organizations (CBOs), etc.\n",
      "\n",
      "These documents help identify eligible vendors for participation in the scheme, card issuance, and access to micro-credit facilities.\n",
      "\n",
      "\n",
      "Query Results:\n",
      "Answer: It appears you are referring to scheme guidelines, possibly related to a specific context such as insurance, financial products, or regulatory frameworks. To provide accurate information, I would need more context about what \"16 | Scheme GuidelineS\" pertains to. Could you please provide more details or clarify your question?\n",
      "Source: https://mohua.gov.in/upload/uploadfiles/files/PMSVANidhi%20Guideline_English.pdf\n",
      "\n",
      "Query system verified successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import faiss\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import pdfplumber\n",
    "from io import BytesIO\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\".config\")  # Load the environment variables from the .config file\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Fetch content\n",
    "def fetch_text_content(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        # Check if the content is a PDF\n",
    "        if 'application/pdf' in response.headers.get('Content-Type', ''):\n",
    "            with pdfplumber.open(BytesIO(response.content)) as pdf:\n",
    "                text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "            return text\n",
    "        else:\n",
    "            # If it's not a PDF, treat it as a webpage\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            return soup.get_text()  # Extract all text from the HTML\n",
    "    else:\n",
    "        return f\"Failed to fetch the content from URL: {url}, Status Code: {response.status_code}\"\n",
    "    \n",
    "# Preprocess text into chunks\n",
    "def preprocess_text(text):\n",
    "    # Split text into chunks of size 500 with overlap of 50 characters\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return splitter.split_text(text)\n",
    "    \n",
    "# Store both text chunks and associated metadata\n",
    "def store_text_and_metadata(text_chunks, url):\n",
    "    metadata = []\n",
    "    for i, chunk in enumerate(text_chunks):\n",
    "        metadata_entry  = {\n",
    "            \"chunk_id\": i,\n",
    "            \"source\": url,\n",
    "            \"page\": i // 10 + 1,  \n",
    "            \"text\": chunk  # Add the text to the metadata entry\n",
    "        }\n",
    "        metadata.append(metadata_entry)\n",
    "    return metadata\n",
    "\n",
    "# Generating a FAISS index\n",
    "def generate_faiss_index(text_chunks_with_metadata):\n",
    "    \n",
    "    # Extract the text from the chunk+metadata structure for FAISS processing\n",
    "    texts = [entry[\"text\"] for entry in text_chunks_with_metadata]\n",
    "    \n",
    "    # Generate embeddings using OpenAI's Embeddings model\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=openai_api_key)\n",
    "    \n",
    "    # Create the FAISS index\n",
    "    faiss_index = FAISS.from_texts(texts, embeddings)\n",
    "    \n",
    "    # Store metadata separately\n",
    "    metadata = {i: entry for i, entry in enumerate(text_chunks_with_metadata)}\n",
    "    \n",
    "    return faiss_index, metadata\n",
    "\n",
    "# Save FAISS index using FAISS's write_index\n",
    "def save_faiss_index(faiss_index, metadata, file_path, metadata_file_path):\n",
    "    # Save the FAISS index to disk\n",
    "    faiss.write_index(faiss_index.index, file_path)\n",
    "    # Save metadata using pickle\n",
    "    with open(metadata_file_path, \"wb\") as f:   \n",
    "        pickle.dump(metadata, f)     \n",
    "\n",
    "# Load FAISS index using FAISS's read_index\n",
    "def load_faiss_index(file_path, metadata_file_path):\n",
    "    # Load the FAISS index from disk\n",
    "    index = faiss.read_index(file_path)\n",
    "    # Load metadata using pickle\n",
    "    with open(metadata_file_path, \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    return index, metadata\n",
    "      \n",
    "# Initialize the OpenAI client with your API key\n",
    "llm = OpenAI(model=\"gpt-4o\", api_key=openai_api_key)\n",
    "\n",
    "# Summarization\n",
    "def summarize_text(text):\n",
    "    prompts = {\n",
    "        \"benefits\": \"Extract and summarize the benefits of the scheme:\",\n",
    "        \"application_process\": \"Describe the application process for the scheme:\",\n",
    "        \"eligibility\": \"Who is eligible for the scheme:\",\n",
    "        \"documents\": \"List the documents required for the scheme:\",\n",
    "    }\n",
    "    summaries = {}\n",
    "    for key, prompt in prompts.items():\n",
    "        response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n{text}\"}\n",
    "                ])\n",
    "        summaries[key] = response.choices[0].message.content\n",
    "    return summaries\n",
    "\n",
    "# Query System \n",
    "def query_system(query, faiss_index, metadata):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=openai_api_key)\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    \n",
    "    # Convert the query embedding to a numpy array and reshape it\n",
    "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "    \n",
    "    # Perform the search\n",
    "    distances, indices = faiss_index.search(query_embedding, k=1)\n",
    "    \n",
    "    # Retrieve the similar texts based on the indices\n",
    "    similar_texts = [metadata[idx][\"text\"] for idx in indices[0]]\n",
    "    \n",
    "        # Iterate over each text and generate a response\n",
    "    answers = []\n",
    "    for text in similar_texts:\n",
    "        # Create a message for the chat model\n",
    "        response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ]\n",
    "            )\n",
    "            # Extract the content of the response\n",
    "        answers.append(response.choices[0].message.content)   \n",
    "       \n",
    "    # Extract source information for each text\n",
    "    sources = [metadata[idx][\"source\"] for idx in indices[0]]\n",
    "    return answers, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use the entire workflow\n",
    "def run_workflow():\n",
    "    # Step 1: Fetch PDF content\n",
    "    url = \"https://mohua.gov.in/upload/uploadfiles/files/PMSVANidhi%20Guideline_English.pdf\"\n",
    "    try:\n",
    "        text = fetch_text_content(url)\n",
    "        print(\"PDF content fetched successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching PDF content: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Preprocess the text into chunks\n",
    "    text_chunks = preprocess_text(text)\n",
    "    print(f\"Text preprocessed into {len(text_chunks)} chunks.\")\n",
    "    \n",
    "    # Step 3: Store text and metadata\n",
    "    text_and_metadata = store_text_and_metadata(text_chunks, url)\n",
    "    \n",
    "    # Step 4: Generate FAISS index with both text and metadata\n",
    "    faiss_index, metadata = generate_faiss_index(text_and_metadata)\n",
    "    \n",
    "    # Step 5: Save the FAISS index and metadata\n",
    "    save_faiss_index(faiss_index, metadata, \"faiss_index.index\", \"faiss_metadata.pkl\")\n",
    "    \n",
    "    # Step 6: Load the FAISS index and metadata for later use\n",
    "    loaded_index, loaded_metadata = load_faiss_index(\"faiss_index.index\", \"faiss_metadata.pkl\")\n",
    "\n",
    "    # Step 7: Summarize the text (new step)\n",
    "    print(\"Starting summarization process...\")\n",
    "    try:\n",
    "        full_text = \" \".join([chunk[\"text\"] for chunk in text_and_metadata])\n",
    "        summaries = summarize_text(full_text)\n",
    "        print(\"Summarization completed.\")\n",
    "        for key, summary in summaries.items():\n",
    "            print(f\"\\nSummary for {key}:\\n{summary}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "    \n",
    "    # Step 8: Query the system to verify that it returns the correct responses\n",
    "    if loaded_index is not None:\n",
    "        query = \"Implementation timeline of the scheme?\"\n",
    "        answers, sources = query_system(query, loaded_index,loaded_metadata)\n",
    "        \n",
    "        print(\"\\nQuery Results:\")\n",
    "        for answer, source in zip(answers, sources):\n",
    "            print(f\"Answer: {answer}\")\n",
    "            print(f\"Source: {source}\")\n",
    "        print(\"\\nQuery system verified successfully!\")\n",
    "\n",
    "# Function to inspect FAISS index and associated metadata\n",
    "def inspect_faiss_index_with_metadata(faiss_index, metadata):\n",
    "    num_vectors = faiss_index.ntotal\n",
    "    print(f\"Number of vectors in FAISS index: {num_vectors}\")\n",
    "    \n",
    "    for i in range(min(1, num_vectors)):  # Check first 5 entries\n",
    "        # Access vector embeddings\n",
    "        vector = faiss_index.reconstruct(i)\n",
    "        print(f\"Vector {i}: {vector}\")\n",
    "        \n",
    "        # Access associated metadata (stored separately)\n",
    "        meta_data = metadata.get(i, None)\n",
    "        print(f\"Metadata for vector {i}: {meta_data}\")\n",
    "\n",
    "# Run the workflow\n",
    "run_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
